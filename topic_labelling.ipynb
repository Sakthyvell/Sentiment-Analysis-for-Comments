{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d82e96cafeeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextblob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "import pandas, xgboost, numpy, textblob, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       So there is no way for me to plug it in here i...\n",
      "1                             Good case, Excellent value.\n",
      "2                                  Great for the jawbone.\n",
      "3       Tied to charger for conversations lasting more...\n",
      "4                                       The mic is great.\n",
      "5       I have to jiggle the plug to get it to line up...\n",
      "6       If you have several dozen or several hundred c...\n",
      "7             If you are Razr owner...you must have this!\n",
      "8                     Needless to say, I wasted my money.\n",
      "9                        What a waste of money and time!.\n",
      "10                        And the sound quality is great.\n",
      "11      He was very impressed when going from the orig...\n",
      "12      If the two were seperated by a mere 5+ ft I st...\n",
      "13                               Very good quality though\n",
      "14      The design is very odd, as the ear \"clip\" is n...\n",
      "15      Highly recommend for any one who has a blue to...\n",
      "16                    I advise EVERYONE DO NOT BE FOOLED!\n",
      "17                                       So Far So Good!.\n",
      "18                                          Works great!.\n",
      "19      It clicks into place in a way that makes you w...\n",
      "20      I went on Motorola's website and followed all ...\n",
      "21      I bought this to use with my Kindle Fire and a...\n",
      "22               The commercials are the most misleading.\n",
      "23      I have yet to run this new battery below two b...\n",
      "24      I bought it for my mother and she had a proble...\n",
      "25                   Great Pocket PC / phone combination.\n",
      "26      I've owned this phone for 7 months now and can...\n",
      "27      I didn't think that the instructions provided ...\n",
      "28      People couldnt hear me talk and I had to pull ...\n",
      "29                                   Doesn't hold charge.\n",
      "                              ...                        \n",
      "1970    I immediately said I wanted to talk to the man...\n",
      "1971                      The ambiance isn't much better.\n",
      "1972    Unfortunately, it only set us up for disapppoi...\n",
      "1973                                The food wasn't good.\n",
      "1974    Your servers suck, wait, correction, our serve...\n",
      "1975        What happened next was pretty....off putting.\n",
      "1976    too bad cause I know it's family owned, I real...\n",
      "1977                 Overpriced for what you are getting.\n",
      "1978                 I vomited in the bathroom mid lunch.\n",
      "1979    I kept looking at the time and it had soon bec...\n",
      "1980    I have been to very few places to eat that und...\n",
      "1981    We started with the tuna sashimi which was bro...\n",
      "1982                              Food was below average.\n",
      "1983    It sure does beat the nachos at the movies but...\n",
      "1984         All in all, Ha Long Bay was a bit of a flop.\n",
      "1985    The problem I have is that they charge $11.99 ...\n",
      "1986    Shrimp- When I unwrapped it (I live only 1/2 a...\n",
      "1987       It lacked flavor, seemed undercooked, and dry.\n",
      "1988    It really is impressive that the place hasn't ...\n",
      "1989    I would avoid this place if you are staying in...\n",
      "1990    The refried beans that came with my meal were ...\n",
      "1991           Spend your money and time some place else.\n",
      "1992    A lady at the table next to us found a live gr...\n",
      "1993              the presentation of the food was awful.\n",
      "1994             I can't tell you how disappointed I was.\n",
      "1995    I think food should have flavor and texture an...\n",
      "1996                             Appetite instantly gone.\n",
      "1997    Overall I was not impressed and would not go b...\n",
      "1998    The whole experience was underwhelming, and I ...\n",
      "1999    Then, as if I hadn't wasted enough of my life ...\n",
      "Name: Comments, Length: 2000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "data = pandas.read_csv(\"/home/sakthy1497/Downloads/Amazon_Review_Dataset - amazon_cells_labelled.csv\")\n",
    "print(data['Comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in data['Comments']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=3, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.024*\"service\" + 0.018*\"great\" + 0.014*\"time\"'), (1, '0.019*\"food\" + 0.017*\"good\" + 0.015*\"place\"'), (2, '0.026*\"phone\" + 0.017*\"great\" + 0.016*\"work\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=5, num_words=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
